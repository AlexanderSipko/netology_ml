# Обучение ML

## **2 Классификация: Логистическая регрессия и SVM**

### Задание

* **Цель:**
  * изучить применение модели логистической регрессии и метода опорных векторов в задаче бинарной классификации.
* **Описание задания:**
  * классификация физических лиц по уровню дохода.
  * Данные для обучения модели хранятся в файле `adult.csv`

* **Целевая переменная**
  
  * уровень дохода `income`, который принимает два значения `<=50K` и `>50K`, поэтому классификация бинарная.
  * Остальные признаки описывают персональную информацию – возраст, образование, семейное положение и т. д. Подробное описание признаков и их возможные значения можно получить самостоятельно, используя функции Python3 для анализа датасета (describe, unique и т.д) или прочитать информацию по ссылке.
  * **Задачу классификации нужно решить при помощи обучения модели логистической регрессии и модели опорных векторов.**

* **Решение**
  * [solution_jupiter](task/2_logic_regression.ipynb)

## **3 Функции потерь и оптимизация**

### Задание

* **Цель:**
  * изучить применение методов оптимизации для решения задачи классификации.
* **Описание задания:**
  * 1 Загрузите данные. `iris` В данных оставьте только 2 класса: Iris `Versicolor`, `Iris Virginica`.
  * 2 Реализовать логистическую регрессию, `LogisticRegression` без библиотеки
    * *Оформите в виде класса с методами.
  * 3 Реализовать метод `градиентного спуска` Обучить логистическую регрессию этим методом. Выбрать и посчитать метрику качества. (выбрать только одну метрику для сравнения)
  * 4 Для п.3 повторить метод скользящего среднего `Root Mean Square Propagation, RMSProp`
  * 5 Для п.3 повторить для ускоренного по Нестерову метода адаптивной оценки моментов `Nesterov–accelerated Adaptive Moment Estimation, Nadam`
  * 6 Сравнить значение метрик для реализованных методов оптимизации. Можно оформить в виде таблицы вида:
  
    | Метод |Метрика | Время |learning_rate|epoch|
    |:-------|:--------:|:--------:|:--------:|:--------:|
    | `Без оптимизации` | 0.85 | 0.00 сек |0.001|	5000
    | `С RMSProp` | 0.85 | 2.671943 | 0.001 | 5000
    | `С Nadam` | 0.85 | 2.943094 | 0.001 | 5000

    * (время работы опционально). Написать вывод.

* **Результат**
  
  * получены навыки реализации методов оптимизации в задаче бинарной классификации. Пройденные методы оптимизации используются и в нейросетях.

* **Решение**
  * [solution_jupiter](task/3_loss%20_function.ipynb)

## **4 Оценка точности модели, переобучение, регуляризация**

### Задание

* **Цель:**
  * закрепить знания о математическом смысле метрик `TPR`, `FPR`. Изучить построение `ROC-кривой`, графика `Precision-Recall.`
* **Описание задания:**
Решить задачу классификации при помощи обучения модели логистической регрессии. Качество модели оценивается путем подсчета метрик `TPR`, `FPR` и построения графиков `ROC-кривой`, `Precision-Recall`. Данные для обучения модели хранятся в файле `athletes.csv`, который можно найти в материалах к занятию.

  * 1 Преобразуйте данные:
    * проверьте наличие пропущенных значений. Преобразуйте/удалите пропуски по необходимости;
    * закодируйте категориальные переменные числовыми значениями по необходимости.
  * 2 Разделите выборку на обучающее (`80% данных`) и тестовое (20% данных) подмножества.
  * 3 Постройте `ROC-кривую` с помощью функции `sklearn.metrics.` `roc_curve.`посчитать метрику качества. (выбрать только одну метрику для сравнения)
  * 4 Вычислите значение `ROC-AUC` метрики с помощью функции `sklearn.metrics.roc_auc_score`.
  * 5 Реализуйте подсчет метрик `TPR`, `FPR «вручную»`, без использования готовых функций из библиотеки `sklearn`.
  * 6 Постройте `ROC-кривую` с помощью вычисленных в п. 5 метрик: объедините графики из п. 3 и п. 6 в один. Сравните, сделайте вывод.
  * 7 Постройте график Precision-Recall, используя метрики, посчитанные в п. 5.
  * 8 *Вычислите значение ROC-AUC метрики, используя метрики, посчитанные в п. 5.
  * 9 Сформулируйте выводы по проделанной работе:
    * как по полученным графикам сделать вывод о качестве модели? Как вы оцениваете обученную модель исходя из подсчитанных метрик?
    * *может ли `ROC-кривая` проходить ниже диагонали?

  * Рекомендации к выполнению:
    * Убедитесь, что на графике `ROC-кривой` присутствует диагональная линия, начинающаяся в точке `(0;0)` и заканчивающаяся в точке `(1;1)`.
    * Текст оформляйте в отдельной ячейке `Jupyter Notebook/Google Colab` в формате markdown.
    * У графиков должен быть заголовок, подписи осей, легенда (опционально). Делайте графики бОльшего размера, чем стандартный вывод, чтобы увеличить читаемость.
    * Убедитесь, что по ссылкам есть доступ на чтение/просмотр.
    * Убедитесь, что все ячейки в работе выполнены и можно увидеть их вывод без повторного запуска.

* **Результат**
  
  * проведена оценка качества модели классификации;
  * реализован подсчет «вручную» основных метрик, проведено сравнение полученных результатов с готовыми функциями из библиотеки `sklearn`.

* **Решение**
  * [solution_jupiter](task/4_Logres_affai.ipynb)

## Вопросы на проработку

### Визуальный анализ данных

* проработать инструменты анализа `sns` & `plt`
