# Обучение ML

[README.MD](/README.MD)

## **14 Улучшение качества модели**

### Задание

* **Цель:**
  * Применить на практике алгоритмы по автоматической оптимизации параметров моделей машинного обучения.

* **Описание задания:**
  * В домашнем задании нужно решить задачу классификации наличия болезни сердца у пациентов наиболее эффективно.
  * Данные для обучения моделей необходимо загрузить самостоятельно с сайта.
  * Целевая переменная – наличие болезни сердца (`HeartDisease`). Она принимает значения `0` или `1` в зависимости от отсутствия или наличия болезни соответственно.
  * Подробное описание признаков можно прочесть в описании датасета на сайте.
  * Для выполнения работы не обязательно вникать в медицинские показатели.

* **Шаги выполнения**
  1. Получите данные и загрузите их в рабочую среду. (Jupyter Notebook или другую)
  2. Подготовьте датасет к обучению моделей
     1. a) Категориальные переменные переведите в цифровые значения. Можно использовать `pd.get_dummies`, `preprocessing.LabelEncoder`. Старайтесь не использовать для этой задачи циклы.
  3. Разделите выборку на обучающее и тестовое подмножество. `80%` данных оставить на обучающее множество, `20%` на тестовое.
  4. Обучите модель `логистической регрессии` с параметрами по умолчанию.
  5. Подсчитайте основные метрики модели. Используйте следующие метрики и функцию:
     1. `cross_validate(…, cv=10, scoring=[‘accuracy’,‘recall’,‘precision’,‘f1’])`
  6. Оптимизируйте 3-4 параметра модели:
     1. a) Используйте `GridSearchCV`.
     2. b) Используйте `RandomizedSearchCV`.
     3. c) *Добавьте в `п.6b` 2-5 моделей классификации и вариации их параметров.
     4. d) Повторите `п.5` после каждого итогового изменения параметров.
  7. Сформулируйте выводы по проделанной работе:
     1. a) Сравните метрики построенных моделей.
     2. b) *Сравните с полученными результатами в домашнем задании по теме `«Ансамблирование»`.

* **Результат**
  
  * Для получения зачета по этому домашнему заданию минимально необходимо:
    * обучить одну модель классификации;
    * оптимизировать параметры, используя метод из `п.6a`;
    * вывести значения метрик.

* **Решение**
  * [solution_jupiter](/task/13%20Claster/13%20claster.ipynb)


Cross-Validation Метрики:| train_score: 0.8719 test_score: 0.8533 | delta: 0.0187
--------------------------------------------------------
Accuracy: 0.8495
Recall: 0.8676
Precision: 0.8671
F1: 0.8629

Подобранные параметры для оптимизации: {'C': 0.1, 'max_iter': 100, 'solver': 'liblinear'}
LogisticRegression Метрика с оптимизированными параметрами GridSearchCV:| train_score: 0.8719 test_score: 0.8533 | delta: 0.0187
--------------------------------------------------------
Accuracy: 0.8506
Recall: 0.8656
Precision: 0.8697
F1: 0.8635

Подобранные параметры для оптимизации: {'C': 0.29617860693636144, 'max_iter': 140, 'solver': 'lbfgs'}
LogisticRegression Метрика с оптимизированными параметрами RandomizedSearchCV:| train_score: 0.8719 test_score: 0.8533 | delta: 0.0187
--------------------------------------------------------
Accuracy: 0.8506
Recall: 0.8696
Precision: 0.8674
F1: 0.8641

RandomForestClassifier Метрика с оптимизированными параметрами RandomizedSearchCV:| train_score: 0.9510 test_score: 0.8804 | delta: 0.0187
--------------------------------------------------------
Accuracy: 0.8583
Recall: 0.8874
Precision: 0.8635
F1: 0.8715

GradientBoostingClassifier Метрика с оптимизированными параметрами RandomizedSearchCV:| train_score: 1.0000 test_score: 0.8804 | delta: 0.0187
--------------------------------------------------------
Accuracy: 0.8528
Recall: 0.8718
Precision: 0.8679
F1: 0.8666

SupportVectorClassifier Метрика с оптимизированными параметрами RandomizedSearchCV:| train_score: 0.9210 test_score: 0.8804 | delta: 0.0187
--------------------------------------------------------
Accuracy: 0.8485
Recall: 0.8756
Precision: 0.8602
F1: 0.8636

KNearestNeighborsClassifier Метрика с оптимизированными параметрами RandomizedSearchCV:| train_score: 1.0000 test_score: 0.8696 | delta: 0.0187
--------------------------------------------------------
Accuracy: 0.8616
Recall: 0.8875
Precision: 0.8695
F1: 0.8755

LogisticRegression Метрика с оптимизированными параметрами GridSearchCV
показала улучшение по сравнению с другими методами 
но при этом 4. ✔✔✔ `BaggingClassifier` с пред обученными моделями `BaggingClassifier` `train` `0.90` BaggingClassifier test `0.88` показывает еще лучший показатель из из другой лекции