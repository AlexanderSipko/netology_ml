# Обучение ML

[README.MD](/README.MD)

## **3 Функции потерь и оптимизация**

### Задание

* **Цель:**
  * изучить применение методов оптимизации для решения задачи классификации.
* **Описание задания:**
  * 1 Загрузите данные. `iris` В данных оставьте только 2 класса: Iris `Versicolor`, `Iris Virginica`.
  * 2 Реализовать логистическую регрессию, `LogisticRegression` без библиотеки
    * *Оформите в виде класса с методами.
  * 3 Реализовать метод `градиентного спуска` Обучить логистическую регрессию этим методом. Выбрать и посчитать метрику качества. (выбрать только одну метрику для сравнения)
  * 4 Для п.3 повторить метод скользящего среднего `Root Mean Square Propagation, RMSProp`
  * 5 Для п.3 повторить для ускоренного по Нестерову метода адаптивной оценки моментов `Nesterov–accelerated Adaptive Moment Estimation, Nadam`
  * 6 Сравнить значение метрик для реализованных методов оптимизации. Можно оформить в виде таблицы вида:
  
    | Метод |Метрика | Время |learning_rate|epoch|
    |:-------|:--------:|:--------:|:--------:|:--------:|
    | `Без оптимизации` | 0.85 | 0.00 сек |0.001|	5000
    | `С RMSProp` | 0.85 | 2.671943 | 0.001 | 5000
    | `С Nadam` | 0.85 | 2.943094 | 0.001 | 5000

    * (время работы опционально). Написать вывод.

* **Результат**
  
  * получены навыки реализации методов оптимизации в задаче бинарной классификации. Пройденные методы оптимизации используются и в нейросетях.

* **Решение**
  * [solution_jupiter](/task/3_loss_function/3_loss%20_function%20copy.ipynb)
